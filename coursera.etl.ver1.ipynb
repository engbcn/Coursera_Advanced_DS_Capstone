{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# ETL notebook", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Install libraries", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Importing standard libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pickle\n\nfrom botocore.client import Config\nimport ibm_boto3"
        }, 
        {
            "source": "Define credentials to access a IBM cloud bucket storage", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "source": "We define a function to read rgb data from a pickle file provided by the customer", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Defining function for loading dataset from 'pickle' file\ndef load_rgb_data(file):\n    # Opening 'pickle' file and getting images\n    with open(file, 'rb') as f:\n        d = pickle.load(f, encoding='latin1')  # dictionary type, we use 'latin1' for python3\n        # At the same time method 'astype()' used for converting ndarray from int to float\n        # It is needed to divide float by float when applying Normalization\n        x = d['features'].astype(np.float32)   # 4D numpy.ndarray type, for train = (34799, 32, 32, 3)\n        y = d['labels']                        # 1D numpy.ndarray type, for train = (34799,)\n        s = d['sizes']                         # 2D numpy.ndarray type, for train = (34799, 2)\n        c = d['coords']                        # 2D numpy.ndarray type, for train = (34799, 4)\n        \"\"\"\n        Data is a dictionary with four keys:\n            'features' - is a 4D array with raw pixel data of the traffic sign images,\n                         (number of examples, width, height, channels).\n            'labels'   - is a 1D array containing the label id of the traffic sign image,\n                         file label_names.csv contains id -> name mappings.\n            'sizes'    - is a 2D array containing arrays (width, height),\n                         representing the original width and height of the image.\n            'coords'   - is a 2D array containing arrays (x1, y1, x2, y2),\n                         representing coordinates of a bounding frame around the image.\n        \"\"\"\n\n    # Returning ready data\n    return x, y, s, c"
        }, 
        {
            "source": "The customer has provided 3 separate sets for training, validation and testing. We load into a dictionary of numpy arrays.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cos.download_file(Bucket=credentials['BUCKET'], Key='train.pickle', Filename='train.pickle')   \ncos.download_file(Bucket=credentials['BUCKET'], Key='valid.pickle', Filename='valid.pickle')\ncos.download_file(Bucket=credentials['BUCKET'], Key='test.pickle', Filename='test.pickle')\ncos.download_file(Bucket=credentials['BUCKET'], Key='label_names.csv', Filename='label_names.csv')\n\n# Loading rgb data from training dataset\nx_train, y_train, s_train, c_train = load_rgb_data('train.pickle')\n#\n# # Loading rgb data from validation dataset\nx_validation, y_validation, s_validation, c_validation = load_rgb_data('valid.pickle')\n#\n# # Loading rgb data from test dataset\nx_test, y_test, s_test, c_test = load_rgb_data('test.pickle')"
        }, 
        {
            "source": "The customer has provided a separate csv file with the description of every class (traffic sign description). We define a function to obtain the description of each class", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# # Getting texts for every class\nlabels = pd.read_csv('label_names.csv', delimiter=',')"
        }, 
        {
            "source": "We define a different set of functions for data augmentation", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# # Putting loaded data into the dictionary\n# # Equalization is done only for training dataset\nd_loaded = {'x_train': x_train, 'y_train': y_train,\n            'x_validation': x_validation, 'y_validation': y_validation,\n            'x_test': x_test, 'y_test': y_test,\n            'labels': labels}"
        }, 
        {
            "source": "We save all the data together in a dictionary", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Saving loaded and preprocessed data into 'pickle' file\nwith open('raw_data.pickle', 'wb') as f:\n    pickle.dump(d_loaded, f)\n    # Releasing memory\ndel d_loaded\n\n#upload feather object\ncos.upload_file(Filename='raw_data.pickle', Bucket=credentials['BUCKET'], Key='raw_data.pickle') "
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}