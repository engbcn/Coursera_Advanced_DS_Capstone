{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Model Definition Notebook "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Logistics Regression"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Install the proper version of tensorFlow and Keras packages"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Import libraries"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport pickle\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\n\nimport matplotlib.pyplot as plt\n\n#from botocore.client import Config\n#import ibm_boto3"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Define credentials to access a IBM cloud bucket storage"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Load the training, validation and testing data"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "x_train:  (86989, 3072)\nx_validation:  (4410, 3072)\nx_test:  (12630, 3072)\ny_train:  (86989,)\ny_validation:  (4410,)\ny_test:  (12630,)\n"
                }
            ],
            "source": "# load data\ndataset = 'data_shuffled_scaled255.pickle'\ncos.download_file(Bucket=credentials['BUCKET'], Key=dataset, Filename=dataset) \n\nwith open(dataset, 'rb') as file:\n    data = pickle.load(file, encoding='latin1')\n\n# transpose for images 32 x 32 x 3    \nx_train = data['x_train'].transpose(0, 2, 3, 1).reshape(data['x_train'].shape[0],-1)\nx_validation = data['x_validation'].transpose(0, 2, 3, 1).reshape(data['x_validation'].shape[0],-1)\nx_test = data['x_test'].transpose(0, 2, 3, 1).reshape(data['x_test'].shape[0],-1)\n\ny_train = data['y_train']\ny_validation = data['y_validation']\ny_test = data['y_test']\n\n# Display shapes\nprint(\"x_train: \", x_train.shape)\nprint(\"x_validation: \", x_validation.shape)\nprint(\"x_test: \", x_test.shape)\nprint(\"y_train: \", y_train.shape)\nprint(\"y_validation: \", y_validation.shape)\nprint(\"y_test: \", y_test.shape)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Solver used is stochastic gradient descent (sag) as it is much faster than default liblinear of lfgbs."
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "scaler = StandardScaler()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Notice the code below has .95 for the number of components parameter. It means that scikit-learn choose the minimum number of principal components such that 95% of the variance is retained."
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "pca = PCA(0.95)"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "# Define the Logistics Regression Model\nlogreg = LogisticRegression(solver='sag', max_iter=200)"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "pipe = Pipeline([('Standard',scaler), ('pca', pca), ('logreg', logreg)])"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n  \"this warning.\", FutureWarning)\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n"
                },
                {
                    "data": {
                        "text/plain": "Pipeline(memory=None,\n     steps=[('Standard', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=0.95, random_state=None,\n  svd_solver='auto', tol=0.0, whiten=False)), ('logreg', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=200, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='sag',\n          tol=0.0001, verbose=0, warm_start=False))])"
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "pipe.fit(x_train, y_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.7754552652414886"
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "pipe.score(x_test, y_test)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Create an instance of Logistic Regression Classifier and fit the data.\nlogreg.fit(x_train, y_train)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "y_predicted = logreg.predict(x_test)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "accuracy_score(y_test,y_predicted)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}